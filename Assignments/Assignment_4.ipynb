{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aJ_pmgxvGur9"
      },
      "source": [
        "# Assignment 4b - Graph Convolutional Networks\n",
        "## Deep Learning Course - Vrije Universiteit Amsterdam, 2022"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mEneMITS2agU"
      },
      "source": [
        "#### Instructions on how to use this notebook:\n",
        "\n",
        "This notebook is hosted on Google Colab. To be able to work on it, you have to create your own copy. Go to *File* and select *Save a copy in Drive*.\n",
        "\n",
        "You can also avoid using Colab entirely, and download the notebook to run it on your own machine. If you choose this, go to *File* and select *Download .ipynb*.\n",
        "\n",
        "The advantage of using Colab is that you can use a GPU. You can complete this assignment with a CPU, but it will take a bit longer. Furthermore, we encourage you to train using the GPU not only for faster training, but also to get experience with this setting. This includes moving models and tensors to the GPU and back. This experience is very valuable because for many interesting models and large datasets (like large CNNs for ImageNet, or Transformer models trained on Wikipedia), training on GPU is the only feasible way.\n",
        "\n",
        "The default Colab runtime does not have a GPU. To change this, go to *Runtime - Change runtime type*, and select *GPU* as the hardware accelerator. The GPU that you get changes according to what resources are available at the time, and its memory can go from a 5GB, to around 18GB if you are lucky. If you are curious, you can run the following in a code cell to check:\n",
        "\n",
        "```sh\n",
        "!nvidia-smi\n",
        "```\n",
        "\n",
        "Note that despite the name, Google Colab does  not support collaborative work without issues. When two or more people edit the notebook concurrently, only one version will be saved. You can choose to do group programming with one person sharing the screen with the others, or make multiple copies of the notebook to work concurrently.\n",
        "\n",
        "**Submission:** Upload your notebook in .ipynb format to Canvas. The code and answers to the questions in the notebook are sufficient, no separate report is expected."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lBgoJIpdLI2Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1624abee-2d4a-4137-baed-2676e5e9c299"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sat Dec  9 22:47:58 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   36C    P8     9W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tsdc7fDp40rQ"
      },
      "source": [
        "### Introduction\n",
        "\n",
        "Graphs are very useful data structures that allow us to represent sets of entities and the way they are related among each other. In a graph, entities are also known as *nodes*, and any link between entities is also called an *edge*.\n",
        "\n",
        "Examples of real world objects that can be modeled as graphs are social networks, where entities are people and relations denote friendship; and molecules, where entities are atoms and relations indicate a bond between them.\n",
        "\n",
        "There has been increased interest in the recent years in the application of deep learning architectures to graph-structured data, for tasks like predicting missing relations between entities, classifying entities, and classifying graphs. This interest has been spurred by the introduction of Graph Convolutional Networks (GCNs).\n",
        "\n",
        "In this assignment, you will implement and experiment with one of the first versions of the GCN, proposed by Thomas Kipf and Max Welling in their 2017 paper, [Semi-supervised Classification with Graph Convolutional Networks](https://arxiv.org/abs/1609.02907). In particular, the goals of this assignment are to\n",
        "\n",
        "- Understand how GCNs are formulated\n",
        "- Implement the GCN using PyTorch\n",
        "- Train and evaluate a model for semi-supervised node classification in citation networks\n",
        "- Train and evaluate a model for binary classification of molecules"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RvsuVNczG6pP"
      },
      "source": [
        "### Representing graphs\n",
        "\n",
        "Suppose we have the following graph:\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/dfdazac/dlvu-a5/main/img/01-graph.png\" width=\"200\">\n",
        "\n",
        "This is an undirected graph (since the edges have no specified direction) with 4 nodes. One way to represent the connectivity structure of the graph is by means of the **adjacency matrix**. The $i$-th row of the matrix contains a 1 in the $j$-th column, if nodes $i$ and $j$ are connected. For an undirected graph like the one above, this means that the adjacency matrix\n",
        "\n",
        "- Is symmetric (e.g. an edge between 0 and 2 is equivalent as an edge between 2 and 0)\n",
        "- Is square, of size $n\\times n$ where $n$ is the number of nodes\n",
        "\n",
        "The adjacency matrix for the graph above is then the following:\n",
        "\n",
        "$$\n",
        "A =\n",
        "\\begin{bmatrix}\n",
        "0 & 0 & 1 & 0 \\\\\n",
        "0 & 0 & 1 & 0 \\\\\n",
        "1 & 1 & 0 & 1 \\\\\n",
        "0 & 0 & 1 & 0\n",
        "\\end{bmatrix}\n",
        "$$\n",
        "\n",
        "A second matrix of interest is the **degree matrix**. This is a diagonal matrix where the $i$-th element of the diagonal indicates the number of edges connected to node $i$. Note that these can be obtained from $A$ by summing across the columns, or the rows. For our example, the degree matrix is\n",
        "\n",
        "$$\n",
        "D = \\begin{bmatrix}\n",
        "1 & 0 & 0 & 0 \\\\\n",
        "0 & 1 & 0 & 0 \\\\\n",
        "0 & 0 & 3 & 0 \\\\\n",
        "0 & 0 & 0 & 1\n",
        "\\end{bmatrix}\n",
        "$$\n",
        "\n",
        "For specific applications, each node in the graph will have an associated vector of features $x\\in\\mathbb{R}^c$. If our graph is a social network, then the vector of features can contain information like age, location, and musical tastes, in a specific numeric format. In the case of a molecule, the node could represent an atom and have features like the atomic mass, etc. We can lay out the features in a matrix $X\\in\\mathbb{R}^{n\\times c}$, so that the feature vector for node $i$ is in the $i$-th row."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zCEQ2ffzHCf2"
      },
      "source": [
        "### Loading a citation network\n",
        "\n",
        "To move to a real world example, we will start with the Cora dataset. This dataset represents a citation network, where nodes are scientific publications, edges denote citations between them, and features are a [bag-of-words](https://en.wikipedia.org/wiki/Bag-of-words_model) extracted from their contents.\n",
        "\n",
        "This graph contains labels for nodes, that represent a specific topic. We will use these for a node classification task.\n",
        "\n",
        "To easily load it, we will use [PyTorch Geometric](https://pytorch-geometric.readthedocs.io/en/latest/index.html) (PyG), a deep learning library for graph-structured data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yd2bTEBADt-a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0121caa8-fd9d-477f-aa8c-18df271baa84"
      },
      "source": [
        "# Install PyTorch Geometric\n",
        "import torch\n",
        "try:\n",
        "    import torch_geometric\n",
        "except ModuleNotFoundError:\n",
        "    # Installing torch geometric packages with specific CUDA+PyTorch version.\n",
        "    # See https://pytorch-geometric.readthedocs.io/en/latest/notes/installation.html for details\n",
        "    TORCH = torch.__version__.split('+')[0]\n",
        "    CUDA = 'cu' + torch.version.cuda.replace('.','')\n",
        "\n",
        "    !pip install torch-scatter     -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n",
        "    !pip install torch-sparse      -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n",
        "    !pip install torch-geometric\n",
        "    import torch_geometric"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://pytorch-geometric.com/whl/torch-2.1.0+cu121.html\n",
            "Collecting torch-scatter\n",
            "  Downloading https://data.pyg.org/whl/torch-2.1.0%2Bcu121/torch_scatter-2.1.2%2Bpt21cu121-cp310-cp310-linux_x86_64.whl (10.8 MB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m10.8/10.8 MB\u001b[0m \u001b[31m32.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch-scatter\n",
            "Successfully installed torch-scatter-2.1.2+pt21cu121\n",
            "Looking in links: https://pytorch-geometric.com/whl/torch-2.1.0+cu121.html\n",
            "Collecting torch-sparse\n",
            "  Downloading https://data.pyg.org/whl/torch-2.1.0%2Bcu121/torch_sparse-0.6.18%2Bpt21cu121-cp310-cp310-linux_x86_64.whl (5.0 MB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m5.0/5.0 MB\u001b[0m \u001b[31m52.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch-sparse) (1.11.4)\n",
            "Requirement already satisfied: numpy<1.28.0,>=1.21.6 in /usr/local/lib/python3.10/dist-packages (from scipy->torch-sparse) (1.23.5)\n",
            "Installing collected packages: torch-sparse\n",
            "Successfully installed torch-sparse-0.6.18+pt21cu121\n",
            "Collecting torch-geometric\n",
            "  Downloading torch_geometric-2.4.0-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (4.66.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.23.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.11.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.1.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (2.31.0)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.1.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.2.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (5.9.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch-geometric) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2023.11.17)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric) (3.2.0)\n",
            "Installing collected packages: torch-geometric\n",
            "Successfully installed torch-geometric-2.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V0Nvh_-qEo1q"
      },
      "source": [
        "We can now use the library to download and import the dataset. Initializing the `Planetoid` class returns a `Dataset` object that can contain multiple graphs. In this task we will only use the `Cora` dataset (the citation network) and hence, we will select only the first element."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vuOvwhsHD2YK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5149bde7-ce89-4e25-9aff-cb334e71355c"
      },
      "source": [
        "from torch_geometric.datasets import Planetoid\n",
        "data = Planetoid(root='data/Planetoid', name='Cora')[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.x\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.tx\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.allx\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.y\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.ty\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.ally\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.graph\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.test.index\n",
            "Processing...\n",
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v4WZkoiHFyZm"
      },
      "source": [
        "\n",
        "#### Question 1 (0.25 pt)\n",
        "\n",
        "The `data` object is an instance of the `Data` class in PyG. Check the [documentation](https://pytorch-geometric.readthedocs.io/en/latest/modules/data.html) and report the following properties of the graph:\n",
        "\n",
        "- Number of nodes\n",
        "- Number of edges\n",
        "- The dimension $c$ of the feature vectors $x\\in\\mathbb{R}^c$\n",
        "- The number of targets for the classification task"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sjVuGJhlJC_7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "859c769e-4209-4f5e-dc9c-0ddb8dc80c66"
      },
      "source": [
        "num_nodes = print(\"number of nodes:\", data.num_nodes)\n",
        "num_edges = print(\"number of edges:\", data.edge_index.size(1))\n",
        "feature_dim = print(\"dimension  ùëê  of the feature vectors  ùë•‚àà‚Ñùùëê:\", data.x.size(1))\n",
        "num_classes = print(\"number of targets for the classification task:\", len(torch.unique(data.y)))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of nodes: 2708\n",
            "number of edges: 10556\n",
            "dimension  ùëê  of the feature vectors  ùë•‚àà‚Ñùùëê: 1433\n",
            "number of targets for the classification task: 7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G4DrGDAuJ2YO"
      },
      "source": [
        "#### Question 2 (0.25 pt)\n",
        "\n",
        "In PyG, edges are provided in a tensor of shape (2, number of edges). You can access it via `data.edge_index`. Each column in this tensor contains the IDs for two nodes that are connected in the graph.\n",
        "\n",
        "We saw that in an undirected graph, an edge between nodes $i$ and $j$ adds a value of 1 to positions $(i, j)$ and $(j, i)$ of the adjacency matrix. Is this also true for the edge index? That is, if there is an edge $(i, j)$ in `data.edge_index`, is there also an edge for $(j, i)$? This is important to know for the next steps of the implementation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jTRfNxibarRZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c762ad8-e6dd-44b1-e047-e71e237488c6"
      },
      "source": [
        "import torch\n",
        "from torch_geometric.datasets import Planetoid\n",
        "\n",
        "data = Planetoid(root='data/Planetoid', name='Cora')[0]\n",
        "\n",
        "edge_index = data.edge_index\n",
        "\n",
        "edges = set(tuple(edge) for edge in edge_index.t().tolist())\n",
        "\n",
        "undirected = all((edge[1], edge[0]) in edges for edge in edges)\n",
        "\n",
        "if undirected:\n",
        "    print(\"graph is undirected\")\n",
        "else:\n",
        "    print(\"graph is directed\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "graph is undirected\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YOpS3QTYiOqp"
      },
      "source": [
        "#### Question 3 (0.5 pt)\n",
        "\n",
        "In graphs, especially large ones, the adjacency matrix is **sparse**: most entries are zero. Sparse matrices allow for efficient storage and computation.\n",
        "\n",
        "To prepare and pre-process sparse matrices, we will use [`scipy.sparse`](https://docs.scipy.org/doc/scipy/reference/sparse.html). Once the matrices are ready, we will convert them to PyTorch tensors.\n",
        "\n",
        "We will use the [Sparse COO format](https://en.wikipedia.org/wiki/Sparse_matrix#Coordinate_list_(COO)). We encourage you to first get familiar with how it works after continuing with the assignment.\n",
        "\n",
        "- Use the [`scipy.sparse.coo_matrix()`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.coo_matrix.html) function to build the adjacency matrix. Think of what arguments are needed, and how you can obtain them from the graph data loaded above.\n",
        "- Use the `sum()` method of sparse matrices, together with `scipy.sparse.diags()`, to compute the degree matrix using the definition above.\n",
        "\n",
        "Both resulting matrices must be sparse of type `float32`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QC01OjbJs92-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cef6465a-ec3d-4ba6-afe5-31ff7e3212e6"
      },
      "source": [
        "import torch\n",
        "from torch_geometric.datasets import Planetoid\n",
        "from scipy.sparse import coo_matrix\n",
        "import numpy as np\n",
        "\n",
        "data = Planetoid(root='data/Planetoid', name='Cora')[0]\n",
        "\n",
        "num_nodes = data.num_nodes\n",
        "\n",
        "edge_index = data.edge_index.numpy()\n",
        "rows, cols = edge_index\n",
        "adj_matrix = coo_matrix((np.ones(len(rows)), (rows, cols)), shape=(num_nodes, num_nodes), dtype=np.float32)\n",
        "\n",
        "degrees = np.array(adj_matrix.sum(axis=1)).flatten()\n",
        "degree_matrix = coo_matrix((degrees, (np.arange(num_nodes), np.arange(num_nodes))), shape=(num_nodes, num_nodes), dtype=np.float32)\n",
        "\n",
        "print(\"adjacency matrix:\")\n",
        "print(adj_matrix)\n",
        "\n",
        "print(\"degree matrix:\")\n",
        "print(degree_matrix)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "adjacency matrix:\n",
            "  (0, 633)\t1.0\n",
            "  (0, 1862)\t1.0\n",
            "  (0, 2582)\t1.0\n",
            "  (1, 2)\t1.0\n",
            "  (1, 652)\t1.0\n",
            "  (1, 654)\t1.0\n",
            "  (2, 1)\t1.0\n",
            "  (2, 332)\t1.0\n",
            "  (2, 1454)\t1.0\n",
            "  (2, 1666)\t1.0\n",
            "  (2, 1986)\t1.0\n",
            "  (3, 2544)\t1.0\n",
            "  (4, 1016)\t1.0\n",
            "  (4, 1256)\t1.0\n",
            "  (4, 1761)\t1.0\n",
            "  (4, 2175)\t1.0\n",
            "  (4, 2176)\t1.0\n",
            "  (5, 1629)\t1.0\n",
            "  (5, 1659)\t1.0\n",
            "  (5, 2546)\t1.0\n",
            "  (6, 373)\t1.0\n",
            "  (6, 1042)\t1.0\n",
            "  (6, 1416)\t1.0\n",
            "  (6, 1602)\t1.0\n",
            "  (7, 208)\t1.0\n",
            "  :\t:\n",
            "  (2694, 431)\t1.0\n",
            "  (2694, 2695)\t1.0\n",
            "  (2695, 431)\t1.0\n",
            "  (2695, 2694)\t1.0\n",
            "  (2696, 2615)\t1.0\n",
            "  (2697, 986)\t1.0\n",
            "  (2698, 1400)\t1.0\n",
            "  (2698, 1573)\t1.0\n",
            "  (2699, 2630)\t1.0\n",
            "  (2700, 1151)\t1.0\n",
            "  (2701, 44)\t1.0\n",
            "  (2701, 2624)\t1.0\n",
            "  (2702, 186)\t1.0\n",
            "  (2702, 1536)\t1.0\n",
            "  (2703, 1298)\t1.0\n",
            "  (2704, 641)\t1.0\n",
            "  (2705, 287)\t1.0\n",
            "  (2706, 165)\t1.0\n",
            "  (2706, 169)\t1.0\n",
            "  (2706, 1473)\t1.0\n",
            "  (2706, 2707)\t1.0\n",
            "  (2707, 165)\t1.0\n",
            "  (2707, 598)\t1.0\n",
            "  (2707, 1473)\t1.0\n",
            "  (2707, 2706)\t1.0\n",
            "degree matrix:\n",
            "  (0, 0)\t3.0\n",
            "  (1, 1)\t3.0\n",
            "  (2, 2)\t5.0\n",
            "  (3, 3)\t1.0\n",
            "  (4, 4)\t5.0\n",
            "  (5, 5)\t3.0\n",
            "  (6, 6)\t4.0\n",
            "  (7, 7)\t1.0\n",
            "  (8, 8)\t3.0\n",
            "  (9, 9)\t2.0\n",
            "  (10, 10)\t2.0\n",
            "  (11, 11)\t2.0\n",
            "  (12, 12)\t4.0\n",
            "  (13, 13)\t2.0\n",
            "  (14, 14)\t5.0\n",
            "  (15, 15)\t4.0\n",
            "  (16, 16)\t4.0\n",
            "  (17, 17)\t5.0\n",
            "  (18, 18)\t5.0\n",
            "  (19, 19)\t1.0\n",
            "  (20, 20)\t5.0\n",
            "  (21, 21)\t2.0\n",
            "  (22, 22)\t5.0\n",
            "  (23, 23)\t1.0\n",
            "  (24, 24)\t7.0\n",
            "  :\t:\n",
            "  (2683, 2683)\t1.0\n",
            "  (2684, 2684)\t2.0\n",
            "  (2685, 2685)\t4.0\n",
            "  (2686, 2686)\t2.0\n",
            "  (2687, 2687)\t2.0\n",
            "  (2688, 2688)\t3.0\n",
            "  (2689, 2689)\t2.0\n",
            "  (2690, 2690)\t1.0\n",
            "  (2691, 2691)\t2.0\n",
            "  (2692, 2692)\t1.0\n",
            "  (2693, 2693)\t1.0\n",
            "  (2694, 2694)\t2.0\n",
            "  (2695, 2695)\t2.0\n",
            "  (2696, 2696)\t1.0\n",
            "  (2697, 2697)\t1.0\n",
            "  (2698, 2698)\t2.0\n",
            "  (2699, 2699)\t1.0\n",
            "  (2700, 2700)\t1.0\n",
            "  (2701, 2701)\t2.0\n",
            "  (2702, 2702)\t2.0\n",
            "  (2703, 2703)\t1.0\n",
            "  (2704, 2704)\t1.0\n",
            "  (2705, 2705)\t1.0\n",
            "  (2706, 2706)\t4.0\n",
            "  (2707, 2707)\t4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AIEJyQi2TzyY"
      },
      "source": [
        "You might wonder why we suggest to use a scipy sparse matrix, while also PyTorch supports them. The reason is that in the next step, we will be multiplying two sparse matrices, an operation not supported in PyTorch. PyTorch only allows multiplying a sparse matrix with a dense one, something which we will be doing at a later stage.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YlmzSb0up4LB"
      },
      "source": [
        "### The Graph Convolutional Network\n",
        "\n",
        "The goal of the graph convolution is to take the feature vectors of all nodes $X\\in\\mathbb{R}^{n\\times c}$, and propagate them along the existing edges, to obtain updated representations $Z\\in\\mathbb{R}^{n\\times d}$.\n",
        "\n",
        "\n",
        "The GCN is initially motivated as performing a convolution, similarly as it is done in CNNs for images, for graph-structured data. In Kipf and Welling (2017), a theoretical derivation leads to the following formula:\n",
        "\n",
        "$$\n",
        "Z = \\tilde{D}^{-\\frac{1}{2}}\\tilde{A}\\tilde{D}^{-\\frac{1}{2}}XW\n",
        "$$\n",
        "\n",
        "where\n",
        "\n",
        "- $W\\in\\mathbb{R}^{c\\times d}$ is a matrix of parameters to be learned via gradient descent\n",
        "- $\\tilde{A} = A + I_n$, where $I_n$ is an $n\\times n$ identity matrix\n",
        "- $\\tilde{D}$ is the degree matrix computed with $\\tilde{A}$ as the adjacency matrix\n",
        "\n",
        "If we define $\\hat{A} = \\tilde{D}^{-\\frac{1}{2}}\\tilde{A}\\tilde{D}^{-\\frac{1}{2}}$, the graph convolution can be written as $Z = \\hat{A}XW$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LL4b-MTvysBp"
      },
      "source": [
        "#### Question 4 (0.25 pt)\n",
        "\n",
        "Given the formula for the GCN, explain why it operates by propagating feature vectors across the graph. To answer this, it might be useful to recall the definitions of the adjacency and degree matrices, and how they are involved in the formula."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vgx2SkTTyiSN"
      },
      "source": [
        "*Your answer here*"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "The GCN formula:Z = D^(-1/2) * A* D~^(-1/2) * X * W operates by propagating and transforming node features across the graph. A is the adjacency matrix with loops which is obtained by adding the identity matrix to the original adjacency matrix. The addition of loops allows each node to consider its own features along with its neighbors‚Äô. D is the degree matrix of A, which counts the connections including its own edges for each node. The formula normalizes A with D^(-1/2) on both sides to balance the influence of each node,. This prevents nodes with many connections from dominating the feature updating process. When this normalized adjacency matrix is multiplied by the feature matrix X, it blends each node's features with those of its neighbors which allowed information to flow through the graph. The final multiplication with the weight matrix, W transforms these features. This is similar to layers in traditional neural networks. This enables GCNs to effectively capture both the graph's structural and the nodes information.\n"
      ],
      "metadata": {
        "id": "qkrDYEHZ0Ykr"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QUGABEqxylsd"
      },
      "source": [
        "#### Question 5 (0.5 pt)\n",
        "\n",
        "Compute the **normalized adjacency matrix** $\\hat{A}$. The result should be a sparse matrix."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GPZbnSaSyDzO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b7ad7a1f-f0c9-41f6-f826-1c2e9417de63"
      },
      "source": [
        "from scipy.sparse import identity\n",
        "\n",
        "adj_self_loops = adj_matrix + identity(num_nodes)\n",
        "\n",
        "deg_self_loops = np.array(adj_self_loops.sum(axis=1)).flatten()\n",
        "deg_mat_self_loops = coo_matrix((np.power(deg_self_loops, -0.5), (np.arange(num_nodes), np.arange(num_nodes))), shape=(num_nodes, num_nodes), dtype=np.float32)\n",
        "\n",
        "norm_adj = deg_mat_self_loops.dot(adj_self_loops).dot(deg_mat_self_loops)\n",
        "\n",
        "print(\"normalized adjacency matrix:\")\n",
        "print(norm_adj)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "normalized adjacency matrix:\n",
            "  (0, 0)\t0.25\n",
            "  (0, 633)\t0.25\n",
            "  (0, 1862)\t0.22360679507255554\n",
            "  (0, 2582)\t0.25\n",
            "  (1, 1)\t0.25\n",
            "  (1, 2)\t0.20412415266036987\n",
            "  (1, 652)\t0.28867512941360474\n",
            "  (1, 654)\t0.3535533845424652\n",
            "  (2, 1)\t0.20412415266036987\n",
            "  (2, 2)\t0.16666667879725594\n",
            "  (2, 332)\t0.16666667879725594\n",
            "  (2, 1454)\t0.2886751401597465\n",
            "  (2, 1666)\t0.15430335304673193\n",
            "  (2, 1986)\t0.05025189181493417\n",
            "  (3, 3)\t0.4999999828857291\n",
            "  (3, 2544)\t0.4999999828857291\n",
            "  (4, 4)\t0.16666667879725594\n",
            "  (4, 1016)\t0.16666667879725594\n",
            "  (4, 1256)\t0.13608277249582912\n",
            "  (4, 1761)\t0.14433757007987325\n",
            "  (4, 2175)\t0.16666667879725594\n",
            "  (4, 2176)\t0.13608277249582912\n",
            "  (5, 5)\t0.25\n",
            "  (5, 1629)\t0.25\n",
            "  (5, 1659)\t0.28867512941360474\n",
            "  :\t:\n",
            "  (2699, 2699)\t0.4999999828857291\n",
            "  (2700, 1151)\t0.4082482761496564\n",
            "  (2700, 2700)\t0.4999999828857291\n",
            "  (2701, 44)\t0.28867512941360474\n",
            "  (2701, 2624)\t0.33333332136784577\n",
            "  (2701, 2701)\t0.33333332136784577\n",
            "  (2702, 186)\t0.21821788274037246\n",
            "  (2702, 1536)\t0.25819888202132546\n",
            "  (2702, 2702)\t0.33333332136784577\n",
            "  (2703, 1298)\t0.4999999828857291\n",
            "  (2703, 2703)\t0.4999999828857291\n",
            "  (2704, 641)\t0.4999999828857291\n",
            "  (2704, 2704)\t0.4999999828857291\n",
            "  (2705, 287)\t0.4999999828857291\n",
            "  (2705, 2705)\t0.4999999828857291\n",
            "  (2706, 165)\t0.1999999952104794\n",
            "  (2706, 169)\t0.25819888202132546\n",
            "  (2706, 1473)\t0.1999999952104794\n",
            "  (2706, 2706)\t0.1999999952104794\n",
            "  (2706, 2707)\t0.1999999952104794\n",
            "  (2707, 165)\t0.1999999952104794\n",
            "  (2707, 598)\t0.07669649645685173\n",
            "  (2707, 1473)\t0.1999999952104794\n",
            "  (2707, 2706)\t0.1999999952104794\n",
            "  (2707, 2707)\t0.1999999952104794\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LLLdGdZoMEy-"
      },
      "source": [
        "#### Question 6 (0.5 pt)\n",
        "\n",
        "So far we have used scipy to build and compute sparse matrices. Since we want to train a GCN with PyTorch, we need to convert $\\hat{A}$ into a sparse PyTorch tensor. You can do this with the [`torch.sparse_coo_tensor()`](https://pytorch.org/docs/stable/generated/torch.sparse_coo_tensor.html) function, making sure to specify `torch.float` as the type."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dgDsVHzEM32F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f7ec00ac-fe6b-41d0-fadc-4ef2c0377e84"
      },
      "source": [
        "import torch\n",
        "\n",
        "rows, cols = norm_adj.nonzero()\n",
        "values = norm_adj.data\n",
        "\n",
        "indices = torch.LongTensor([rows, cols])\n",
        "values_tensor = torch.FloatTensor(values)\n",
        "shape = norm_adj.shape\n",
        "\n",
        "norm_adj_matrix = torch.sparse_coo_tensor(indices, values_tensor, torch.Size(shape))\n",
        "\n",
        "print(\"normalized adjacency matrix:\")\n",
        "print(norm_adj_matrix )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "normalized adjacency matrix:\n",
            "tensor(indices=tensor([[   0,    0,    0,  ..., 2707, 2707, 2707],\n",
            "                       [   0,  633, 1862,  ..., 1473, 2706, 2707]]),\n",
            "       values=tensor([0.2500, 0.2500, 0.2236,  ..., 0.2000, 0.2000, 0.2000]),\n",
            "       size=(2708, 2708), nnz=13264, layout=torch.sparse_coo)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-8-9e42bf939c33>:6: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:261.)\n",
            "  indices = torch.LongTensor([rows, cols])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eAlRVT5aODkX"
      },
      "source": [
        "#### Question 7 (0.5 pt)\n",
        "\n",
        "We now have all the ingredients to build a GCN layer. Implement a class (inheriting from `torch.nn.Module`) with a learnable matrix of weights $W\\in\\mathbb{R}^{c\\times d}$. Make sure to\n",
        "\n",
        "- Call this class `GCNLayer`\n",
        "- The `__init__()` constructor should take as argument the number of input and output features.\n",
        "- Use `torch.nn.init.kaiming_uniform_` to initialize $W$.\n",
        "- Define the `forward` method, which takes as input $X$ and $\\hat{A}$ and returns $Z$. Note that multiplications involving the sparse matrix $\\hat{A}$ have to be done with `torch.spmm`.\n",
        "\n",
        "Once you have implemented the class, instantiate a layer with the correct number of input features for the Cora dataset, and a number of output features of your choice. Do a forward pass and report the shape of the output tensor."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JFCohhhwPpTT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b4a2cac-d446-44ea-9799-dfbcf5d4d591"
      },
      "source": [
        "# Your answer here\n",
        "import torch\n",
        "import torch_geometric\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as nnfunction\n",
        "from torch_geometric.datasets import Planetoid\n",
        "\n",
        "class GCNLayer(nn.Module):\n",
        "    def __init__(self,input_size,output_size):\n",
        "        super(GCNLayer, self).__init__()\n",
        "        # Create a learnable weight matrix using nn.parameter\n",
        "        w = nn.Parameter(torch.Tensor(input_size, output_size))\n",
        "        # Initialize W using kaiming_uniform\n",
        "        self.w = nn.init.kaiming_uniform_(w, mode='fan_in', nonlinearity='relu')\n",
        "\n",
        "    def forward(self,x,A_hat):\n",
        "        _ = torch.spmm(A_hat,x)\n",
        "        Z = torch.mm(_,self.w)\n",
        "        return Z\n",
        "\n",
        "input_features = data.x.size(1) #using feature_dim from question 1\n",
        "output_features = 5\n",
        "\n",
        "#  Instantiate GCNLayer\n",
        "demo_layer = GCNLayer(input_features, output_features)\n",
        "\n",
        "# Forward\n",
        "input_x = data.x # retrieve the feature matrix\n",
        "result = demo_layer.forward(input_x,norm_adj_matrix)\n",
        "\n",
        "print(\"The shape of the output is:\",result.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The shape of the output is: torch.Size([2708, 5])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ptAiizZUKaM"
      },
      "source": [
        "#### Question 8 (0.5 pt)\n",
        "\n",
        "As we have seen so far, the GCN layer implements a special type of linear transformation of the inputs. However, it is often beneficial in deep learning to stack multiple, non-linear transformations of the input features. Implement a second module class for a model with two GCN layers (use the module you implemented in the previous question).\n",
        "\n",
        "- Call this class `GCN`\n",
        "- The constructor must now take as input the number of input features, the output dimension of the first layer (this is the hidden layer), and the output dimension of the output layer.\n",
        "- In the forward pass, add a ReLU activation function after the first layer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2zhyu3S9Vj3b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86bb2639-a895-48dc-8103-7708838f8a09"
      },
      "source": [
        "# Your answer here\n",
        "class GCN(nn.Module):\n",
        "    def __init__(self,input_size,hidden_size,output_size):\n",
        "        super(GCN, self).__init__()\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "\n",
        "        self.GCN_one = GCNLayer(input_size,hidden_size)\n",
        "        self.GCN_two = GCNLayer(hidden_size,output_size)\n",
        "\n",
        "    def forward(self,x,A_hat):\n",
        "        output_one = self.GCN_one(x,A_hat)\n",
        "        output_one_relu = nnfunction.relu(output_one)\n",
        "        output_two = self.GCN_two(output_one_relu,A_hat)\n",
        "        return output_two\n",
        "\n",
        "input_features = data.x.size(1) #using feature_dim from question 1\n",
        "output_features = 5\n",
        "#  Instantiate GCNLayer\n",
        "demo_stacked_layer = GCN(input_features, output_features,output_features)\n",
        "# Forward\n",
        "input_x = data.x # retrieve the feature matrix\n",
        "stacked_result = demo_stacked_layer.forward(input_x,norm_adj_matrix)\n",
        "print(\"The shape of the output is:\",stacked_result.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The shape of the output is: torch.Size([2708, 5])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6NVB-3I5Wfkf"
      },
      "source": [
        "### GCNs for semi-supervised node classification\n",
        "\n",
        "Now that we have a GCN with two layers, we can test its performance in a node classification task. We will pass the input node features $X$ through the GCN layers, and the output will be of size $n\\times k$ where $k$ is the number of classes (which you found in question 1). The label denotes the topic an article in the citation network belongs to (e.g. physics, computer science, etc.)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "trc4dSa7cuQj"
      },
      "source": [
        "#### Question 9 (1.5 pt)\n",
        "\n",
        "Note that the `data` object contains all labels (for all splits) in `data.y`, and binary masks for the train, validation, and test splits in `data.train_mask`, `data.val_mask`, and `data.test_mask`, respectively. These masks are the same size as `data.y`, and indicate which labels belong to which split.\n",
        "\n",
        "- Create a GCN with two layers (using the class from the previous question), with 32 as the hidden dimension, and the number of output features equal to the number of classes in the Cora dataset.\n",
        "\n",
        "- Use the Adam optimizer with a learning rate of 0.01.\n",
        "\n",
        "- Implement a training loop for the GCN. At each step, pass $X$ and $\\hat{A}$ to the GCN to obtain the logits. Compute the mean cross-entropy loss **only for the training instances**, using the binary masks.\n",
        "\n",
        "- After each training step, evaluate the accuracy for the validation instances.\n",
        "\n",
        "- Train for 100 epochs. Once training is finished, plot the training loss and validation accuracy (in a graph in function of the epoch number), and report the accuracy in the test set.\n",
        "\n",
        "You should obtain an accuracy over 75% on both the validation and test sets. You can also compare your results with the original paper, which also contains results for the Cora dataset. Give a brief discussion on the results of your experiments.\n",
        "\n",
        "Note that in contrast with other tasks, like image classification on some datasets, we don't use mini-batches here. The whole matrix of features and the adjacency is passed to the GCN in one step."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Z2OP_ZRWlmo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "94e38173-0c6f-4375-b36b-d09b99a72e58"
      },
      "source": [
        "# Your answer here\n",
        "import torch.optim as optim\n",
        "input_features = data.x.size(1) #using feature_dim from question 1\n",
        "output_features = len(torch.unique(data.y))\n",
        "hidden_dim = 32\n",
        "epochs = 100\n",
        "input_x = data.x\n",
        "\n",
        "# Split the dataset\n",
        "x_train,y_train = data.x[data.train_mask],data.y[data.train_mask]\n",
        "x_val,y_val = data.x[data.val_mask],data.y[data.val_mask]\n",
        "x_test,y_test = data.x[data.test_mask],data.y[data.test_mask]\n",
        "\n",
        "# Instantiate GCNLayer\n",
        "stacked_layer = GCN(input_features, hidden_dim,output_features)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(stacked_layer.parameters(), lr=0.01)\n",
        "\n",
        "# Monitor result\n",
        "train_loss = []\n",
        "val_acc = []\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    #trainning\n",
        "    result = stacked_layer.forward(input_x,norm_adj_matrix)\n",
        "    loss = criterion(result[data.train_mask], y_train)\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    train_loss.append(loss.item())\n",
        "    #Validation\n",
        "    val_result = stacked_layer.forward(input_x,norm_adj_matrix)\n",
        "    val_label = val_result[data.val_mask].argmax(1)\n",
        "    correct = torch.eq(val_label, y_val)\n",
        "    accuracy = torch.mean(correct.float())\n",
        "    val_acc.append(accuracy.item())\n",
        "    print(\"Traing loss | \",loss.item(),\"Validation accuracy \",accuracy.item())\n",
        "\n",
        "test_result = stacked_layer.forward(input_x,norm_adj_matrix)\n",
        "test_label = test_result[data.test_mask].argmax(1)\n",
        "correct = torch.eq(test_label, y_test)\n",
        "accuracy = torch.mean(correct.float())\n",
        "print(\"Test_accuracy:\",accuracy)\n",
        "\n",
        "#Plotting\n",
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize=(12, 5))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(train_loss, label='Training Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(val_acc, label='Validation Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Validation Accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traing loss |  2.2687501907348633 Validation accuracy  0.23000000417232513\n",
            "Traing loss |  1.7490298748016357 Validation accuracy  0.3199999928474426\n",
            "Traing loss |  1.3744176626205444 Validation accuracy  0.4020000100135803\n",
            "Traing loss |  1.0788646936416626 Validation accuracy  0.4580000042915344\n",
            "Traing loss |  0.8320608139038086 Validation accuracy  0.5299999713897705\n",
            "Traing loss |  0.631276547908783 Validation accuracy  0.5860000252723694\n",
            "Traing loss |  0.47331875562667847 Validation accuracy  0.6340000033378601\n",
            "Traing loss |  0.354574054479599 Validation accuracy  0.6660000085830688\n",
            "Traing loss |  0.26645493507385254 Validation accuracy  0.6940000057220459\n",
            "Traing loss |  0.2006223499774933 Validation accuracy  0.7099999785423279\n",
            "Traing loss |  0.15038785338401794 Validation accuracy  0.7200000286102295\n",
            "Traing loss |  0.11196666210889816 Validation accuracy  0.7200000286102295\n",
            "Traing loss |  0.08308775722980499 Validation accuracy  0.722000002861023\n",
            "Traing loss |  0.0619300976395607 Validation accuracy  0.7279999852180481\n",
            "Traing loss |  0.046683862805366516 Validation accuracy  0.7300000190734863\n",
            "Traing loss |  0.035699572414159775 Validation accuracy  0.734000027179718\n",
            "Traing loss |  0.02767070382833481 Validation accuracy  0.7379999756813049\n",
            "Traing loss |  0.021782446652650833 Validation accuracy  0.7440000176429749\n",
            "Traing loss |  0.017400408163666725 Validation accuracy  0.7440000176429749\n",
            "Traing loss |  0.01411318127065897 Validation accuracy  0.7419999837875366\n",
            "Traing loss |  0.011612492613494396 Validation accuracy  0.7440000176429749\n",
            "Traing loss |  0.009691535495221615 Validation accuracy  0.7400000095367432\n",
            "Traing loss |  0.008192581124603748 Validation accuracy  0.7379999756813049\n",
            "Traing loss |  0.007005411200225353 Validation accuracy  0.7400000095367432\n",
            "Traing loss |  0.00604638596996665 Validation accuracy  0.7400000095367432\n",
            "Traing loss |  0.0052607059478759766 Validation accuracy  0.7400000095367432\n",
            "Traing loss |  0.004609016235917807 Validation accuracy  0.7400000095367432\n",
            "Traing loss |  0.004065028391778469 Validation accuracy  0.7400000095367432\n",
            "Traing loss |  0.0036091203801333904 Validation accuracy  0.7419999837875366\n",
            "Traing loss |  0.0032270599622279406 Validation accuracy  0.7419999837875366\n",
            "Traing loss |  0.002905838657170534 Validation accuracy  0.7440000176429749\n",
            "Traing loss |  0.0026350419502705336 Validation accuracy  0.7480000257492065\n",
            "Traing loss |  0.0024047011975198984 Validation accuracy  0.7459999918937683\n",
            "Traing loss |  0.002207734389230609 Validation accuracy  0.7459999918937683\n",
            "Traing loss |  0.002038082107901573 Validation accuracy  0.7480000257492065\n",
            "Traing loss |  0.0018901907606050372 Validation accuracy  0.7480000257492065\n",
            "Traing loss |  0.0017605002503842115 Validation accuracy  0.7480000257492065\n",
            "Traing loss |  0.001646309974603355 Validation accuracy  0.7480000257492065\n",
            "Traing loss |  0.0015455639222636819 Validation accuracy  0.7480000257492065\n",
            "Traing loss |  0.001456526224501431 Validation accuracy  0.7480000257492065\n",
            "Traing loss |  0.0013778152642771602 Validation accuracy  0.7480000257492065\n",
            "Traing loss |  0.0013083284720778465 Validation accuracy  0.7480000257492065\n",
            "Traing loss |  0.0012467646738514304 Validation accuracy  0.7480000257492065\n",
            "Traing loss |  0.0011920364340767264 Validation accuracy  0.7480000257492065\n",
            "Traing loss |  0.0011432606261223555 Validation accuracy  0.7480000257492065\n",
            "Traing loss |  0.00109969696495682 Validation accuracy  0.7480000257492065\n",
            "Traing loss |  0.001060541602782905 Validation accuracy  0.7480000257492065\n",
            "Traing loss |  0.00102527707349509 Validation accuracy  0.7480000257492065\n",
            "Traing loss |  0.000993326772004366 Validation accuracy  0.7480000257492065\n",
            "Traing loss |  0.0009642909863032401 Validation accuracy  0.7480000257492065\n",
            "Traing loss |  0.0009378124377690256 Validation accuracy  0.7480000257492065\n",
            "Traing loss |  0.0009135138825513422 Validation accuracy  0.7480000257492065\n",
            "Traing loss |  0.0008911601034924388 Validation accuracy  0.7480000257492065\n",
            "Traing loss |  0.000870518502779305 Validation accuracy  0.7480000257492065\n",
            "Traing loss |  0.0008513850625604391 Validation accuracy  0.75\n",
            "Traing loss |  0.0008335778256878257 Validation accuracy  0.75\n",
            "Traing loss |  0.0008169670472852886 Validation accuracy  0.75\n",
            "Traing loss |  0.000801430142018944 Validation accuracy  0.75\n",
            "Traing loss |  0.000786850112490356 Validation accuracy  0.75\n",
            "Traing loss |  0.0007731743389740586 Validation accuracy  0.75\n",
            "Traing loss |  0.0007602928671985865 Validation accuracy  0.75\n",
            "Traing loss |  0.0007480969652533531 Validation accuracy  0.75\n",
            "Traing loss |  0.0007365758647210896 Validation accuracy  0.75\n",
            "Traing loss |  0.0007256482494994998 Validation accuracy  0.75\n",
            "Traing loss |  0.0007152555626817048 Validation accuracy  0.7519999742507935\n",
            "Traing loss |  0.000705340935382992 Validation accuracy  0.7519999742507935\n",
            "Traing loss |  0.0006958686280995607 Validation accuracy  0.7519999742507935\n",
            "Traing loss |  0.0006867880583740771 Validation accuracy  0.7519999742507935\n",
            "Traing loss |  0.0006780805997550488 Validation accuracy  0.7540000081062317\n",
            "Traing loss |  0.0006697138887830079 Validation accuracy  0.7540000081062317\n",
            "Traing loss |  0.0006616830942220986 Validation accuracy  0.7540000081062317\n",
            "Traing loss |  0.0006539097521454096 Validation accuracy  0.7540000081062317\n",
            "Traing loss |  0.0006464324542321265 Validation accuracy  0.7540000081062317\n",
            "Traing loss |  0.0006392017821781337 Validation accuracy  0.7540000081062317\n",
            "Traing loss |  0.0006321872351691127 Validation accuracy  0.7540000081062317\n",
            "Traing loss |  0.0006254069157876074 Validation accuracy  0.7540000081062317\n",
            "Traing loss |  0.0006188162369653583 Validation accuracy  0.7540000081062317\n",
            "Traing loss |  0.0006123857456259429 Validation accuracy  0.7540000081062317\n",
            "Traing loss |  0.000606146058999002 Validation accuracy  0.7540000081062317\n",
            "Traing loss |  0.0006000606226734817 Validation accuracy  0.7540000081062317\n",
            "Traing loss |  0.0005941336276009679 Validation accuracy  0.7540000081062317\n",
            "Traing loss |  0.000588349939789623 Validation accuracy  0.7540000081062317\n",
            "Traing loss |  0.0005827011191286147 Validation accuracy  0.7540000081062317\n",
            "Traing loss |  0.000577203871216625 Validation accuracy  0.7540000081062317\n",
            "Traing loss |  0.0005718116881325841 Validation accuracy  0.7540000081062317\n",
            "Traing loss |  0.0005665245116688311 Validation accuracy  0.7540000081062317\n",
            "Traing loss |  0.0005613485118374228 Validation accuracy  0.7540000081062317\n",
            "Traing loss |  0.0005562817095778883 Validation accuracy  0.7540000081062317\n",
            "Traing loss |  0.0005513107171282172 Validation accuracy  0.7540000081062317\n",
            "Traing loss |  0.0005464133573696017 Validation accuracy  0.7540000081062317\n",
            "Traing loss |  0.0005416117492131889 Validation accuracy  0.7540000081062317\n",
            "Traing loss |  0.0005368804559111595 Validation accuracy  0.7540000081062317\n",
            "Traing loss |  0.000532247475348413 Validation accuracy  0.7540000081062317\n",
            "Traing loss |  0.0005276899901218712 Validation accuracy  0.7540000081062317\n",
            "Traing loss |  0.0005231959512457252 Validation accuracy  0.7540000081062317\n",
            "Traing loss |  0.0005188027280382812 Validation accuracy  0.7540000081062317\n",
            "Traing loss |  0.0005144705064594746 Validation accuracy  0.7540000081062317\n",
            "Traing loss |  0.0005102018476463854 Validation accuracy  0.7540000081062317\n",
            "Traing loss |  0.0005059908726252615 Validation accuracy  0.7540000081062317\n",
            "Traing loss |  0.0005018434603698552 Validation accuracy  0.7540000081062317\n",
            "Test_accuracy: tensor(0.7700)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x500 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the above results, it can be observed that in our results, both the validation and test sets achieved an accuracy rate higher than 75%, yet still lower than the 81.5% accuracy rate reported in the paper results. This discrepancy may be attributed to the original paper incorporating optimization methods such as L2 regularization and Dropout, which enhanced the model's performance."
      ],
      "metadata": {
        "id": "8fMJOto3WxU1"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vb5YjHVClCqo"
      },
      "source": [
        "#### Question 10 (0.5 pt)\n",
        "\n",
        "The paper introduces GCNs as a way to solve a *semi-supervised* classification problem.\n",
        "\n",
        "- What makes this problem semi-supervised?\n",
        "- What is the proportion of labeled data used for training with respect to labeled data in the validation and test sets? What is difference in this context with other benchmark tasks in machine learning, like image classification with MNIST?\n",
        "- Why do you think the GCN performs well in this semi-supervised scenario?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7qw58r1MmCUJ"
      },
      "source": [
        "# Your answer here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer:\n",
        "\n",
        "a) In the mentioned paper, the problem is classified as semi-supervised due to the classification of nodes within a graph where only a small subset of nodes are labelled. This scenario, combining a limited amount of labelled data with a larger volume of unlabeled data, epitomizes semi-supervised learning. The paper addresses this challenge effectively by applying graph convolutional networks to graph-structured data\n",
        "\n",
        "b) The data split proportion was as follows:\n",
        "\n",
        "Training Set: 140 nodes for training. (8.5%)\n",
        "Validation Set: 500 nodes for validation. (30.5%)\n",
        "Test Set: 1000 nodes for testing. (61%)\n",
        "\n",
        "In the Cora dataset, labelled data used for training represents only a tiny fraction of the total data (one out of 140 nodes). In contrast, in the MNIST dataset, most of the data (one out of 60,000 training images) is used for training. Furthermore, the division of the Cora dataset reflects the need for semi-supervised learning, which utilizes a small amount of labelled data with a large amount of unlabeled data. At the same time, the MNIST dataset was divided primarily to adequately train the supervised learning model and evaluate it on a larger test set.\n",
        "\n",
        "c) The reasons contain the following:\n",
        "\n",
        "GCN overcomes the limitations of graph Laplacian regularization-based approaches: Traditional graph Laplacian regularization-based approaches can be limited because they assume that edges only represent similarities between nodes. GCN efficiently captures complex relationships between nodes by operating directly on the graph.\n",
        "\n",
        "Optimization Simplification: Compared to Skip-gram-based methods, GCN avoids complex multi-step processing procedures that are often difficult to optimize.\n",
        "\n",
        "Efficient propagation of feature information: GCN improves classification performance by propagating feature information from neighbouring nodes in each layer, outperforming methods that only aggregate label information, such as ICA."
      ],
      "metadata": {
        "id": "ocu-R8mzuN33"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ihrjZddvz5d"
      },
      "source": [
        "### Loading a dataset of proteins\n",
        "\n",
        "In the previous sections you learned how to pass the adjacency matrix of a graph with a couple of thousand of nodes, to classify each node with a particular label. A different and useful application of GCNs is graph classification.\n",
        "\n",
        "In contrast with the previous part, where there was a single, big graph, in graph classification we have multiple graphs, and each graph can be assigned a label. In this part of the assignment you will implement a classifier for proteins.\n",
        "\n",
        "[Proteins](https://en.wikipedia.org/wiki/Protein_(nutrient)) are parts of the buildings block of life. They consist of chains of amino acids, and can take many shapes. In the PROTEINS dataset, proteins are represented as graphs, where the nodes are amino acids, and an edge between them indicates that they are 6 [Angstroms](https://en.wikipedia.org/wiki/Angstrom) apart. All graphs have a binary label, where 1 means that the protein is not an enzyme.\n",
        "\n",
        "We will start by loading and examining this dataset."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# If there is 'ModuleNotFoundError'\n",
        "# !pip install torch-geometric"
      ],
      "metadata": {
        "id": "qz2R1GizOQc7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xmqweMcvnUH6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b81375c-779d-4c2e-d55c-8bea0328681e"
      },
      "source": [
        "from torch_geometric.datasets import TUDataset\n",
        "dataset = TUDataset(root='data/TU', name='PROTEINS', use_node_attr=True)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading https://www.chrsmrrs.com/graphkerneldatasets/PROTEINS.zip\n",
            "Extracting data/TU/PROTEINS/PROTEINS.zip\n",
            "Processing...\n",
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_oF1gyKPXiz-"
      },
      "source": [
        "#### Question 11 (0.25 pt)\n",
        "\n",
        "Unlike in the previous part, where we selected the first element returned by the loading function, note that here we get all the elements returned by `TUDataset()`. `dataset` is an interable object, that has some similar behaviors as a Python list: you can call `len()` on it, and you can takes slices from it.\n",
        "\n",
        "Each element in `dataset` is a `Data` object containing a graph that represents a protein. This is the same type of object that we used in the previous part to store the Cora citation network.\n",
        "\n",
        "Knowing this, answer the following:\n",
        "\n",
        "- How many proteins (graphs) are there in `dataset`?\n",
        "- Take any protein from `dataset`. How many nodes and edges does it contain? What is its label? How many features does each node have?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZNPsnXXbbHHe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "deb29c32-3a9d-49e0-d25a-451f8ed57f70"
      },
      "source": [
        "# Your answer here\n",
        "test_protein = dataset[0]\n",
        "print(\"The number of protein is:\", len(dataset))\n",
        "print(\"The number of nodes of one protein is:\",test_protein.num_nodes)\n",
        "print(\"The number of edges of one protein is:\",test_protein.num_edges//2)\n",
        "print(\"The number of features of one protein is:\",test_protein.num_node_features)\n",
        "print(\"The label of one protein is:\",test_protein.y.item())"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The number of protein is: 1113\n",
            "The number of nodes of one protein is: 42\n",
            "The number of edges of one protein is: 81\n",
            "The number of features of one protein is: 4\n",
            "The label of one protein is: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kHSklBZXpKpR"
      },
      "source": [
        "#### Question 12 (0.5 pt)\n",
        "\n",
        "To properly train and evaluate our model, we need training, validation, and test splits.\n",
        "\n",
        "For reproducibility purposes, we generate a random tensor of indices for you. Use it to extract the three splits from `dataset`.\n",
        "\n",
        "For training, take 80% of the indices (starting from the first element in `indices`), then the following 10% for validation, and the remaining 10% for testing. You can use the indices to index `dataset`.\n",
        "\n",
        "Call the resulting splits `train_dataset`, `valid_dataset`, and `test_dataset`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ttY4d1GInn08"
      },
      "source": [
        "# Don't erase the following three lines\n",
        "import torch\n",
        "torch.random.manual_seed(0)\n",
        "indices = torch.randperm(len(dataset))\n",
        "\n",
        "# Your answer here\n",
        "total = len(dataset)\n",
        "train_indices = indices[:int(0.8*total)]\n",
        "val_indices = indices[int(0.8*total):(int(0.9*total))]\n",
        "test_indices = indices[int(0.9*total):]\n",
        "train_dataset = torch.utils.data.Subset(dataset, train_indices)\n",
        "valid_dataset = torch.utils.data.Subset(dataset, val_indices)\n",
        "test_dataset = torch.utils.data.Subset(dataset, test_indices)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rDJbB4CQqsfp"
      },
      "source": [
        "### Working with a batch of graphs\n",
        "\n",
        "When working with the Cora dataset, you used the information in `data.edge_index` to build the sparse normalized adjacency matrix $\\hat{A}$ that is required by the GCN. We could do something similar here: for each graph, we build $\\hat{A}$, and pass it to the GCN. However, if the number of graphs is big, this can really slow down training.\n",
        "\n",
        "To avoid this, we will resort to a very useful trick that also allows us to reuse the same GCN you implemented previously. The trick makes it possible to do a forward pass through the GCN for multiple, disconnected graphs at the same time (instead of only one), much like when you train with mini-batches for other kinds of data.\n",
        "\n",
        "Let's first revisit the propagation rule of the GCN, $Z = \\hat{A}XW$, with an illustration (we have omitted the cells of $X$ and $W$ for clarity):\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/dfdazac/dlvu-a5/main/img/02-gcn-forward.png\">\n",
        "\n",
        "If we have multiple graphs, we can still use the same propagation rule, if we\n",
        "\n",
        "- Set $\\hat{A}$ to be a block diagonal matrix, where the blocks are the different adjacency matrices of the graphs\n",
        "- Concatenate the feature matrices along the first dimension\n",
        "\n",
        "This is illustrated in the following figure, for a batch of 3 graphs. Note that the elements outside of the blocks are zero.\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/dfdazac/dlvu-a5/main/img/02-gcn-batch-forward.png\">\n",
        "\n",
        "The resulting adjacency matrix $\\hat{A}_B$ can also be built as a sparse matrix, and once we have it together with the concatenated matrix of features, the computation of the graph convolution is exactly the same as before. Note how this trick also allows us to process graphs with different sizes and structures.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0DLPJ62b2mQ6"
      },
      "source": [
        "#### Question 13 (0.5 pt)\n",
        "\n",
        "\n",
        "Just as the citation network, the graphs in each of the datasets you created in Question 12 also have an `edge_index` attribute, which can be used to compute the normalized adjacency matrix $\\hat{A}$, for each graph.\n",
        "\n",
        "Reusing your code for Questions 3 and 5, define a function `get_a_norm()` that takes as input an element of a dataset (e.g. `train_dataset[0]`), and returns a `scipy.sparse` matrix containing $\\hat{A}$.\n",
        "\n",
        "Note that an element of a dataset has properties like `num_edges`, `num_nodes`, etc. which you can use here."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4nvPX2GB8oXp"
      },
      "source": [
        "# Your answer here\n",
        "from scipy.sparse import coo_matrix, diags\n",
        "import numpy as np\n",
        "\n",
        "from scipy.sparse import coo_matrix, diags, eye\n",
        "\n",
        "def get_a_norm(data):\n",
        "    # indexes and adjacency matrix\n",
        "    edge_index = data.edge_index.numpy()\n",
        "    num_nodes = data.num_nodes\n",
        "    rows, cols = edge_index\n",
        "    values = np.ones(rows.shape[0]*2)\n",
        "    adj_matrix = coo_matrix(\n",
        "        (values, (np.hstack([rows, cols]), np.hstack([cols, rows]))),\n",
        "        shape=(num_nodes, num_nodes)\n",
        "    )\n",
        "\n",
        "    adj_matrix = adj_matrix + eye(num_nodes)\n",
        "\n",
        "    # inverse square root\n",
        "    degrees = np.array(adj_matrix.sum(1)).flatten()\n",
        "    degrees_inv_sqrt = 1. / np.sqrt(degrees)\n",
        "    degree_matrix_inv_sqrt = diags(degrees_inv_sqrt)\n",
        "\n",
        "    # normalized adjacency matrix\n",
        "    norm_adj_matrix = degree_matrix_inv_sqrt @ adj_matrix @ degree_matrix_inv_sqrt\n",
        "\n",
        "    return norm_adj_matrix\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cBrmYBY3AfhW"
      },
      "source": [
        "#### Question 14 (1 pt)\n",
        "\n",
        "To prepare the batch of graphs, we need to collect multiple adjacency matrices, feature matrices, and labels.\n",
        "\n",
        "When using the trick described in the last figure, we see that we have to keep track of when a graph starts and when it ends, so that we can later differentiate the outputs due to $X^{(0)}$, $X^{(1)}$, etc. To achieve this, we will additionally collect a 1D array of batch indices, one for each $X^{(i)}$.\n",
        "\n",
        "The 1D array has as many elements as rows in $X^{(i)}$, and it is filled with the value $i$ (the position of $X^{(i)}$ in the batch):\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/dfdazac/dlvu-a5/main/img/03-batch-indices.png\">\n",
        "\n",
        "We will later concatenate all the 1D arrays along the first dimension, just as we will do with all the $X^{(i)}$.\n",
        "\n",
        "Define a function `prepare_graphs_batch()` that takes as input a dataset (e.g. `train_dataset`), and does the following\n",
        "\n",
        "- Create four empty lists:\n",
        "  - `adj_matrices`\n",
        "  - `feature_matrices`\n",
        "  - `batch_indices`\n",
        "  - `labels`\n",
        "- Iterate over the input dataset, getting one graph at a time. At each step, use your function from Question 13 to append the adjacency matrix to `adj_matrices`, append the matrix of input features to `feature_matrices`, create the array of batch indices (as explained above) and append it to `batch_indices`, and append the label of the graph to `labels`. **Make sure to convert the label to float**.\n",
        "- Once the loop is over, use `scipy.sparse.block_diag()` to build the block diagonal matrix $\\hat{A}_B$. Convert it to the COO format, and then use your answer to Question 6 to turn it into a sparse PyTorch tensor.\n",
        "- Use `torch.cat()` to concatenate the tensors in `feature_matrices` along the first dimension. Do this also for `batch_indices` and `labels`.\n",
        "- Return the 4 tensors computed in the previous two items."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SsQ0-JjSqFgD"
      },
      "source": [
        "# Your answer here\n",
        "from scipy.sparse import block_diag\n",
        "import torch\n",
        "\n",
        "def prepare_graphs_batch(dataset):\n",
        "    adj_matrices = []\n",
        "    feature_matrices = []\n",
        "    batch_indices = []\n",
        "    labels = []\n",
        "\n",
        "    for i, data in enumerate(dataset):\n",
        "        adj_matrices.append(get_a_norm(data).tocoo())\n",
        "        feature_matrices.append(data.x)\n",
        "        batch_indices.append(torch.full((data.num_nodes,), i, dtype=torch.long))\n",
        "        labels.append(data.y.float())\n",
        "\n",
        "    A_B = block_diag([adj.tocsr() for adj in adj_matrices])\n",
        "    A_B = A_B.tocoo()\n",
        "\n",
        "    indices = torch.LongTensor([A_B.row, A_B.col])\n",
        "\n",
        "    A_B_tensor = torch.sparse_coo_tensor(\n",
        "        indices,\n",
        "        torch.FloatTensor(A_B.data),\n",
        "        A_B.shape\n",
        "    )\n",
        "\n",
        "    X_B = torch.cat(feature_matrices, dim=0)\n",
        "    batch_indices_tensor = torch.cat(batch_indices, dim=0)\n",
        "    labels_tensor = torch.cat(labels, dim=0)\n",
        "\n",
        "    return A_B_tensor, X_B, batch_indices_tensor, labels_tensor"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i73P_EU0MSPX"
      },
      "source": [
        "Once your answer for the previous question is ready, you can run the next cell to prepare all the required information, for the train, validation, and test splits."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iol5FxJGMmAU"
      },
      "source": [
        "train_a_norm, train_features, train_batch_idx, train_labels = prepare_graphs_batch(train_dataset)\n",
        "valid_a_norm, valid_features, valid_batch_idx, valid_labels = prepare_graphs_batch(valid_dataset)\n",
        "test_a_norm, test_features, test_batch_idx, test_labels = prepare_graphs_batch(test_dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R6q-JU87NClh"
      },
      "source": [
        "### GCNs for graph classification\n",
        "\n",
        "We now have all the ingredients to pass a batch of graphs to a GCN. However, for each graph in the batch, the output $Z^{(i)}$ contains one row for each node in the graph. If the goal is to do classification at the graph level, we have to *pool* these vectors to then compute the required logits for classification.\n",
        "\n",
        "This operation is similar as how pooling works in a CNN. We could consider taking the mean of the vectors, the sum, or use max-pooling. The difference with respect to CNNs is that in our case, we have a batch of graphs, each potentially with a different number of nodes.\n",
        "\n",
        "To implement this specific pooling, we can use the scatter operation in the `torch_scatter` library, which comes when installing PyG. We will use it, together with the tensor of batch indices from the previous two questions, to pool the outputs of the GCN for each graph, into a single vector:\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/dfdazac/dlvu-a5/main/img/04-scatter.png\">\n",
        "\n",
        "You can check more details in the [documentation](https://pytorch-scatter.readthedocs.io/en/latest/functions/scatter.html)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QY87DX1uRhnY"
      },
      "source": [
        "#### Question 15 (1.0 pt)\n",
        "\n",
        "Implement a `GraphClassifier` module using PyTorch.\n",
        "\n",
        "- The constructor should take as arguments the number of input features, the hidden dimension, and the number of classes.\n",
        "- The model should contain a instance of the `GCN` module (as you implemented it in Question 8). Use the same value for the hidden dimension and the number of output features (recall that your `GCN` module from Question 8 has two GCN layers).\n",
        "- The model should also contain a `torch.nn.Linear` layer, with the hidden dimension as the input features, and the number of classes as the output.\n",
        "- The forward method receives the concatenated matrix of features, the sparse block diagonal adjacency matrix, and the batch indices (the latter is used when calling `scatter`).\n",
        "- Use the following architecture in the forward pass:\n",
        "  - GCN $\\to$ ReLU $\\to$ scatter (max) $\\to$ Linear.\n",
        "\n",
        "The output of the forward should be a 1D tensor (you might need to call `squeeze` to get rid of extra dimensions) containing the logits for all graphs in the batch, for the binary classification task."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure CUDA version compatibility\n",
        "# import torch\n",
        "# print(torch.__version__)\n",
        "# print(torch.version.cuda)\n",
        "# 2.1.0+cu121\n",
        "# 12.1\n",
        "\n",
        "# if there is ModuleNotFoundError about scatter:\n",
        "# !pip uninstall torch-scatter -y\n",
        "# !pip install torch-scatter -f https://pytorch-geometric.com/whl/torch-2.1.0+cu121.html\n"
      ],
      "metadata": {
        "id": "1AlpnuFhIyc7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "750WraywwYDH"
      },
      "source": [
        "# Your answer here\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch_scatter import scatter_max\n",
        "\n",
        "class GraphClassifier(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, num_classes):\n",
        "        super(GraphClassifier, self).__init__()\n",
        "\n",
        "        # Initialize GCN\n",
        "        self.gcn = GCN(input_dim, hidden_dim, hidden_dim)\n",
        "\n",
        "        # Linear\n",
        "        self.linear = nn.Linear(hidden_dim, num_classes)\n",
        "\n",
        "    def forward(self, x, A_B, batch_indices):\n",
        "        x = self.gcn(x, A_B)\n",
        "\n",
        "        # There is no need to apply the ReLU activation function again, as it has already been applied in the GCN layer\n",
        "        x_pool, _ = scatter_max(x, batch_indices, dim=0)\n",
        "\n",
        "        # Linear\n",
        "        logits = self.linear(x_pool)\n",
        "\n",
        "        logits = logits.squeeze()\n",
        "\n",
        "        return logits\n",
        "\n",
        "class GCNLayer(nn.Module):\n",
        "    def __init__(self, input_size, output_size):\n",
        "        super(GCNLayer, self).__init__()\n",
        "        # weight matrix\n",
        "        self.w = nn.Parameter(torch.Tensor(input_size, output_size))\n",
        "        # ‰ΩøÁî®kaiming_uniformÂàùÂßãÂåñ\n",
        "        nn.init.kaiming_uniform_(self.w, mode='fan_in', nonlinearity='relu')\n",
        "\n",
        "    def forward(self, x, A_hat):\n",
        "        # graph convolution operation\n",
        "        support = torch.spmm(A_hat, x)\n",
        "        Z = torch.mm(support, self.w)\n",
        "        return Z\n",
        "\n",
        "class GCN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(GCN, self).__init__()\n",
        "        self.gcn1 = GCNLayer(input_size, hidden_size)\n",
        "        self.gcn2 = GCNLayer(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, x, A_hat):\n",
        "        x = F.relu(self.gcn1(x, A_hat))\n",
        "        x = self.gcn2(x, A_hat)\n",
        "        return x\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C1PHy-_vTjgh"
      },
      "source": [
        "#### Question 16 (1.5 pt)\n",
        "\n",
        "Implement a training loop for the graph classifier. Use the data from Question 14 to train and evaluate the model.\n",
        "\n",
        "We encourage you to use a GPU in this section for faster training. Note that if you change the runtime at this point, you must re-execute several of the cells above, including the ones that install PyG.\n",
        "\n",
        "- Instantiate a classifier with 32 as the hidden dimension\n",
        "- Use Adam with a learning rate of 1e-3.\n",
        "- Use `torch.nn.BCEWithLogitsLoss` as the loss function.\n",
        "- Train for 5,000 epochs. Once training is done, plot the loss curve and the accuracy in the validation set. Then report the accuracy in the test set.\n",
        "\n",
        "**Note:** the logits from the output of the classifier come from a linear layer. To compute actual predictions for the calculation of the accuracy, pass the logits through `torch.sigmoid()`, and set the predicted values to 1 whenever they are greater than 0.5, and to 0 otherwise.\n",
        "\n",
        "You should get an accuracy equal to or higher than 70% in the validation and test sets. Can you beat the [state-of-the-art](https://paperswithcode.com/sota/graph-classification-on-proteins)? Feel free to modify your architecture and experiment with it.\n",
        "\n",
        "Discuss what you observe during training and your results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9DbGAs8W2Xja",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ab644832-d2db-4586-972c-c5a2d84c275a"
      },
      "source": [
        "# If your runtime is GPU-enabled, use .to(device) to move the model\n",
        "# and all the relevant tensors to the GPU. You have to move tensors back to CPU\n",
        "# when computing metrics like accuracy, using .cpu().\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "# Your answer here\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Check GPU\n",
        "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "model = GraphClassifier(input_dim=train_features.shape[1], hidden_dim=32, num_classes=1).to(device)\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
        "\n",
        "criterion = torch.nn.BCEWithLogitsLoss()\n",
        "\n",
        "# prepare data\n",
        "def prepare_data(dataset):\n",
        "    A, X, batch_indices, labels = prepare_graphs_batch(dataset)\n",
        "    return A.to(device), X.to(device), batch_indices.to(device), labels.to(device)\n",
        "\n",
        "train_A, train_X, train_batch_idx, train_labels = prepare_data(train_dataset)\n",
        "valid_A, valid_X, valid_batch_idx, valid_labels = prepare_data(valid_dataset)\n",
        "test_A, test_X, test_batch_idx, test_labels = prepare_data(test_dataset)\n",
        "\n",
        "# training\n",
        "def train():\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    logits = model(train_X, train_A, train_batch_idx)\n",
        "    loss = criterion(logits, train_labels)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    return loss.item()\n",
        "\n",
        "# validation\n",
        "def validate():\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        logits = model(valid_X, valid_A, valid_batch_idx)\n",
        "        predictions = torch.sigmoid(logits) > 0.5\n",
        "        correct = (predictions == valid_labels).sum().item()\n",
        "        return correct / len(valid_labels)\n",
        "\n",
        "# Training and validation\n",
        "losses = []\n",
        "val_accuracies = []\n",
        "\n",
        "for epoch in range(5000):\n",
        "    loss = train()\n",
        "    if epoch % 100 == 0:\n",
        "        val_acc = validate()\n",
        "        val_accuracies.append(val_acc)\n",
        "        print(f\"Epoch {epoch}, Loss: {loss}, Validation Accuracy: {val_acc}\")\n",
        "    losses.append(loss)\n",
        "\n",
        "# result of the 5000th\n",
        "loss = train()\n",
        "val_acc = validate()\n",
        "val_accuracies.append(val_acc)\n",
        "print(f\"Epoch 5000, Loss: {loss}, Validation Accuracy: {val_acc}\")\n",
        "\n",
        "# loss curves\n",
        "plt.figure(figsize=(10, 4))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(losses)\n",
        "plt.title(\"Training Loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "\n",
        "# validation accuracy curve\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(val_accuracies)\n",
        "plt.title(\"Validation Accuracy\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.show()\n",
        "\n",
        "# accuracy of the test set\n",
        "def test():\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        logits = model(test_X, test_A, test_batch_idx)\n",
        "        predictions = torch.sigmoid(logits) > 0.5\n",
        "        correct = (predictions == test_labels).sum().item()\n",
        "        return correct / len(test_labels)\n",
        "\n",
        "test_acc = test()\n",
        "print(f\"Test Accuracy: {test_acc}\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, Loss: 0.6293536424636841, Validation Accuracy: 0.7207207207207207\n",
            "Epoch 100, Loss: 0.5961557626724243, Validation Accuracy: 0.7297297297297297\n",
            "Epoch 200, Loss: 0.5644866228103638, Validation Accuracy: 0.7207207207207207\n",
            "Epoch 300, Loss: 0.5484504103660583, Validation Accuracy: 0.7567567567567568\n",
            "Epoch 400, Loss: 0.5371850728988647, Validation Accuracy: 0.7747747747747747\n",
            "Epoch 500, Loss: 0.5272728204727173, Validation Accuracy: 0.7837837837837838\n",
            "Epoch 600, Loss: 0.5144784450531006, Validation Accuracy: 0.7927927927927928\n",
            "Epoch 700, Loss: 0.5018688440322876, Validation Accuracy: 0.7927927927927928\n",
            "Epoch 800, Loss: 0.4915409982204437, Validation Accuracy: 0.7927927927927928\n",
            "Epoch 900, Loss: 0.4843033254146576, Validation Accuracy: 0.8018018018018018\n",
            "Epoch 1000, Loss: 0.47872060537338257, Validation Accuracy: 0.8198198198198198\n",
            "Epoch 1100, Loss: 0.47248175740242004, Validation Accuracy: 0.8198198198198198\n",
            "Epoch 1200, Loss: 0.46728694438934326, Validation Accuracy: 0.8198198198198198\n",
            "Epoch 1300, Loss: 0.4638706147670746, Validation Accuracy: 0.8198198198198198\n",
            "Epoch 1400, Loss: 0.4602087140083313, Validation Accuracy: 0.8288288288288288\n",
            "Epoch 1500, Loss: 0.4571114778518677, Validation Accuracy: 0.8288288288288288\n",
            "Epoch 1600, Loss: 0.4540599286556244, Validation Accuracy: 0.8288288288288288\n",
            "Epoch 1700, Loss: 0.45077061653137207, Validation Accuracy: 0.8378378378378378\n",
            "Epoch 1800, Loss: 0.4481137990951538, Validation Accuracy: 0.8288288288288288\n",
            "Epoch 1900, Loss: 0.4455502927303314, Validation Accuracy: 0.8378378378378378\n",
            "Epoch 2000, Loss: 0.4427984654903412, Validation Accuracy: 0.8378378378378378\n",
            "Epoch 2100, Loss: 0.4405461251735687, Validation Accuracy: 0.8378378378378378\n",
            "Epoch 2200, Loss: 0.4378366470336914, Validation Accuracy: 0.8378378378378378\n",
            "Epoch 2300, Loss: 0.4352017343044281, Validation Accuracy: 0.8378378378378378\n",
            "Epoch 2400, Loss: 0.43321534991264343, Validation Accuracy: 0.8378378378378378\n",
            "Epoch 2500, Loss: 0.43126749992370605, Validation Accuracy: 0.8468468468468469\n",
            "Epoch 2600, Loss: 0.4291422963142395, Validation Accuracy: 0.8468468468468469\n",
            "Epoch 2700, Loss: 0.42725199460983276, Validation Accuracy: 0.8378378378378378\n",
            "Epoch 2800, Loss: 0.4254445731639862, Validation Accuracy: 0.8378378378378378\n",
            "Epoch 2900, Loss: 0.4236171543598175, Validation Accuracy: 0.8468468468468469\n",
            "Epoch 3000, Loss: 0.421639621257782, Validation Accuracy: 0.8468468468468469\n",
            "Epoch 3100, Loss: 0.4193693995475769, Validation Accuracy: 0.8468468468468469\n",
            "Epoch 3200, Loss: 0.41752293705940247, Validation Accuracy: 0.8468468468468469\n",
            "Epoch 3300, Loss: 0.4152223765850067, Validation Accuracy: 0.8558558558558559\n",
            "Epoch 3400, Loss: 0.4129463732242584, Validation Accuracy: 0.8378378378378378\n",
            "Epoch 3500, Loss: 0.4108133912086487, Validation Accuracy: 0.8558558558558559\n",
            "Epoch 3600, Loss: 0.40929141640663147, Validation Accuracy: 0.8558558558558559\n",
            "Epoch 3700, Loss: 0.4079177677631378, Validation Accuracy: 0.8378378378378378\n",
            "Epoch 3800, Loss: 0.40622591972351074, Validation Accuracy: 0.8468468468468469\n",
            "Epoch 3900, Loss: 0.404649943113327, Validation Accuracy: 0.8558558558558559\n",
            "Epoch 4000, Loss: 0.4033196270465851, Validation Accuracy: 0.8378378378378378\n",
            "Epoch 4100, Loss: 0.4018794000148773, Validation Accuracy: 0.8468468468468469\n",
            "Epoch 4200, Loss: 0.4007750153541565, Validation Accuracy: 0.8378378378378378\n",
            "Epoch 4300, Loss: 0.3996482491493225, Validation Accuracy: 0.8378378378378378\n",
            "Epoch 4400, Loss: 0.39848676323890686, Validation Accuracy: 0.8378378378378378\n",
            "Epoch 4500, Loss: 0.3980503976345062, Validation Accuracy: 0.8378378378378378\n",
            "Epoch 4600, Loss: 0.39660701155662537, Validation Accuracy: 0.8558558558558559\n",
            "Epoch 4700, Loss: 0.395193874835968, Validation Accuracy: 0.8378378378378378\n",
            "Epoch 4800, Loss: 0.39422985911369324, Validation Accuracy: 0.8378378378378378\n",
            "Epoch 4900, Loss: 0.3934458792209625, Validation Accuracy: 0.8468468468468469\n",
            "Epoch 5000, Loss: 0.3921312689781189, Validation Accuracy: 0.8378378378378378\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x400 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 0.7232142857142857\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Discussion:\n",
        "\n",
        "(1) Training Loss: The loss curve indicates that the model learns and improves over time. After an initial rapid decline, the loss gradually levels off, indicating near convergence.\n",
        "\n",
        "(2) Validation Accuracy: Accuracy improves with increasing epoch, showing the model's ability to learn. Despite slight fluctuations, the accuracy stays at a high level, showing good generalization.\n",
        "\n",
        "(3) Test Accuracy: The accuracy of the test set reaches 72.3%, demonstrating that the model has reasonable prediction ability for unknown data, although slightly lower than the validation set performance.\n",
        "\n",
        "(4) Overfitting: Small fluctuations in the accuracy curve at some points may mean that some epochs are slightly overfitted on the validation set. But overall, the generalization performance of the model is improving.\n",
        "\n",
        "(5) Early Stopping: The implementation of early stopping can be considered as a preventive measure. Avoid continuing ineffective training when the accuracy is no longer improving, so as to save time and computational resources. A \"patience\" parameter can be set to stop training if the accuracy does not improve after a certain number of epochs; second, although the current risk of overfitting is not high, early stopping can be used as a precautionary measure to prevent performance degradation in future training.\n",
        "\n",
        "(6) Possible Strategies for Improvement:\n",
        "> (a) Regularization: If fluctuations are a sign of overfitting, try adding a Dropout layer or using L2 regularization.\n",
        "\n",
        "> (b) Activation functions and optimizers: try different activation functions (e.g. LeakyReLU) or other optimizers (e.g. AdamW).\n",
        "\n",
        "> (c) Pooling strategies: improved graph pooling methods, such as using global average pooling or attention mechanisms, may better summarize graph features.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "pqQx2Wh2H3E2"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MvmAfDNMcnKD"
      },
      "source": [
        "## The end\n",
        "\n",
        "If you have made it all the way here successfully, congratulations! üéâ\n",
        "\n",
        "You have implemented your own GCN and tested it on a node classification task, and a more challenging classification task over multiple graphs.\n",
        "\n",
        "We hope you can use this knowledge to apply GCNs not only to the tasks described here, but other applications where data can be modeled as a graph.\n",
        "\n",
        "If you are interested in applying graph neural networks to larger graphs, or try newer architectures, you can dive deeper into [PyTorch Geometric](https://pytorch-geometric.readthedocs.io/en/latest/), a library with fast implementations for a wide range of architectures. It also comes with custom code that takes care of aspects that you dealt with manually for this assignment, like a more efficient implementation of the adjacency matrix multiplication via message-passing methods, and Data Loaders that relieve you from having to build block diagonal sparse matrices.\n",
        "\n",
        "You can also check the [Deep Graph Library](https://docs.dgl.ai/) another powerful library for deep learning on graphs which also integrates with other backends like TensorFlow."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l7QhyAMms8-L"
      },
      "source": [
        "# Grading (10pt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "juIdxXhos-mV"
      },
      "source": [
        "- Question 1: 0.25pt\n",
        "- Question 2: 0.25pt\n",
        "- Question 3: 0.5pt\n",
        "- Question 4: 0.25pt\n",
        "- Question 5: 0.5pt\n",
        "- Question 6: 0.5pt\n",
        "- Question 7: 0.5pt\n",
        "- Question 8: 0.5pt\n",
        "- Question 9: 1.5pt\n",
        "- Question 10: 0.5pt\n",
        "- Question 11: 0.25pt\n",
        "- Question 12: 0.5pt\n",
        "- Question 13: 0.5pt\n",
        "- Question 14: 1pt\n",
        "- Question 15: 1pt\n",
        "- Question 16: 1.5pt"
      ]
    }
  ]
}